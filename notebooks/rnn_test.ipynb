{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kawiki.txt', 'data3.txt', 'data.txt', 'data_115000.txt', 'data2.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "print(os.listdir(\"../data/\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from utils import GeorgianLanguageDatasetLoader\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "dataset = GeorgianLanguageDatasetLoader(\"../data/data_115000.txt\", 5, device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', ',', '.', 'და', ')', '(', '„', '“', 'წელს', '—', 'იყო', 'წლის', ':', 'რომელიც', 'შემდეგ', 'რომ', 'მისი', '``', 'ამ', \"''\"]\n"
     ]
    }
   ],
   "source": [
    "vocab = dataset.get_vocabulary()\n",
    "print(vocab.get_itos()[:20])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 910,  644,  517,  691, 9915,    1,   13,  154,  509, 1907])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, valid_data, test_data = dataset.get_data()\n",
    "train_data[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'მინდა გემორჩილო და ბატონად გაღიაროვო “ . მსოფლიო ბანკი დანიას ევროკავშირში ბიზნესის ყველაზე ადვილად კეთების ადგილად მიიჩნევს . ქაოსი ('"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([vocab.get_itos()[i] for i in train_data[40:60]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "[364, 342, 4857]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline = dataset.get_text_pipeline()\n",
    "text_pipeline(\"შავი კაცი მიდიოდა\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "train_data_batched, val_data_batched = dataset.get_batched_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([5, 158221]), device(type='cpu'))"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_batched.shape, train_data_batched.device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "x, y = utils.get_batch(train_data_batched, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([5, 10]), torch.Size([5, 10]), torch.Size([5, 158221]))"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape, train_data_batched.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.storage().data_ptr() == train_data_batched.storage().data_ptr()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([ 644,  517,  691, 9915,    1,   13,  154,  509, 1907, 3464]),\n tensor([ 517,  691, 9915,    1,   13,  154,  509, 1907, 3464, 1095]))"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0], y[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misho/anaconda3/envs/nlp_final_project/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'batch': 0, 'loss': 11.65722942352295}\n",
      "{'epoch': 1, 'batch': 0, 'loss': 11.572833061218262}\n",
      "{'epoch': 2, 'batch': 0, 'loss': 11.498726844787598}\n",
      "{'epoch': 3, 'batch': 0, 'loss': 11.41809368133545}\n",
      "{'epoch': 4, 'batch': 0, 'loss': 11.350907325744629}\n",
      "{'epoch': 5, 'batch': 0, 'loss': 11.2488431930542}\n",
      "{'epoch': 6, 'batch': 0, 'loss': 11.152766227722168}\n",
      "{'epoch': 7, 'batch': 0, 'loss': 11.028532981872559}\n",
      "{'epoch': 8, 'batch': 0, 'loss': 10.830387115478516}\n",
      "{'epoch': 9, 'batch': 0, 'loss': 10.58997917175293}\n",
      "{'epoch': 10, 'batch': 0, 'loss': 10.226019859313965}\n",
      "{'epoch': 11, 'batch': 0, 'loss': 9.704802513122559}\n",
      "{'epoch': 12, 'batch': 0, 'loss': 9.00595474243164}\n",
      "{'epoch': 13, 'batch': 0, 'loss': 8.119498252868652}\n",
      "{'epoch': 14, 'batch': 0, 'loss': 7.096694469451904}\n",
      "{'epoch': 15, 'batch': 0, 'loss': 6.022543430328369}\n",
      "{'epoch': 16, 'batch': 0, 'loss': 5.041867256164551}\n",
      "{'epoch': 17, 'batch': 0, 'loss': 4.189472198486328}\n",
      "{'epoch': 18, 'batch': 0, 'loss': 3.599033832550049}\n",
      "{'epoch': 19, 'batch': 0, 'loss': 3.209195137023926}\n",
      "{'epoch': 20, 'batch': 0, 'loss': 2.9805679321289062}\n",
      "{'epoch': 21, 'batch': 0, 'loss': 2.8556554317474365}\n",
      "{'epoch': 22, 'batch': 0, 'loss': 2.769747734069824}\n",
      "{'epoch': 23, 'batch': 0, 'loss': 2.7182977199554443}\n",
      "{'epoch': 24, 'batch': 0, 'loss': 2.6637051105499268}\n",
      "{'epoch': 25, 'batch': 0, 'loss': 2.613013982772827}\n",
      "{'epoch': 26, 'batch': 0, 'loss': 2.5823943614959717}\n",
      "{'epoch': 27, 'batch': 0, 'loss': 2.561621904373169}\n",
      "{'epoch': 28, 'batch': 0, 'loss': 2.508183240890503}\n",
      "{'epoch': 29, 'batch': 0, 'loss': 2.4558563232421875}\n",
      "{'epoch': 30, 'batch': 0, 'loss': 2.4211411476135254}\n",
      "{'epoch': 31, 'batch': 0, 'loss': 2.3696465492248535}\n",
      "{'epoch': 32, 'batch': 0, 'loss': 2.3260297775268555}\n",
      "{'epoch': 33, 'batch': 0, 'loss': 2.289515256881714}\n",
      "{'epoch': 34, 'batch': 0, 'loss': 2.2536275386810303}\n",
      "{'epoch': 35, 'batch': 0, 'loss': 2.22735333442688}\n",
      "{'epoch': 36, 'batch': 0, 'loss': 2.1975457668304443}\n",
      "{'epoch': 37, 'batch': 0, 'loss': 2.1627743244171143}\n",
      "{'epoch': 38, 'batch': 0, 'loss': 2.1163623332977295}\n",
      "{'epoch': 39, 'batch': 0, 'loss': 2.093033790588379}\n",
      "{'epoch': 40, 'batch': 0, 'loss': 2.0475709438323975}\n",
      "{'epoch': 41, 'batch': 0, 'loss': 2.1066935062408447}\n",
      "{'epoch': 42, 'batch': 0, 'loss': 1.9630279541015625}\n",
      "{'epoch': 43, 'batch': 0, 'loss': 1.9438105821609497}\n",
      "{'epoch': 44, 'batch': 0, 'loss': 1.9077849388122559}\n",
      "{'epoch': 45, 'batch': 0, 'loss': 1.8749462366104126}\n",
      "{'epoch': 46, 'batch': 0, 'loss': 1.8456846475601196}\n",
      "{'epoch': 47, 'batch': 0, 'loss': 1.7717998027801514}\n",
      "{'epoch': 48, 'batch': 0, 'loss': 1.7487226724624634}\n",
      "{'epoch': 49, 'batch': 0, 'loss': 1.7269574403762817}\n",
      "{'epoch': 50, 'batch': 0, 'loss': 1.6724663972854614}\n",
      "{'epoch': 51, 'batch': 0, 'loss': 1.660252571105957}\n",
      "{'epoch': 52, 'batch': 0, 'loss': 1.6160529851913452}\n",
      "{'epoch': 53, 'batch': 0, 'loss': 1.569006323814392}\n",
      "{'epoch': 54, 'batch': 0, 'loss': 1.5425817966461182}\n",
      "{'epoch': 55, 'batch': 0, 'loss': 1.5000450611114502}\n",
      "{'epoch': 56, 'batch': 0, 'loss': 1.4609193801879883}\n",
      "{'epoch': 57, 'batch': 0, 'loss': 1.437772512435913}\n",
      "{'epoch': 58, 'batch': 0, 'loss': 1.3922690153121948}\n",
      "{'epoch': 59, 'batch': 0, 'loss': 1.3423893451690674}\n",
      "{'epoch': 60, 'batch': 0, 'loss': 1.3070385456085205}\n",
      "{'epoch': 61, 'batch': 0, 'loss': 1.2896956205368042}\n",
      "{'epoch': 62, 'batch': 0, 'loss': 1.236507773399353}\n",
      "{'epoch': 63, 'batch': 0, 'loss': 1.1908745765686035}\n",
      "{'epoch': 64, 'batch': 0, 'loss': 1.1652754545211792}\n",
      "{'epoch': 65, 'batch': 0, 'loss': 1.1226714849472046}\n",
      "{'epoch': 66, 'batch': 0, 'loss': 1.0969411134719849}\n",
      "{'epoch': 67, 'batch': 0, 'loss': 1.0523176193237305}\n",
      "{'epoch': 68, 'batch': 0, 'loss': 1.0335110425949097}\n",
      "{'epoch': 69, 'batch': 0, 'loss': 0.978715717792511}\n",
      "{'epoch': 70, 'batch': 0, 'loss': 0.9248354434967041}\n",
      "{'epoch': 71, 'batch': 0, 'loss': 0.9267272353172302}\n",
      "{'epoch': 72, 'batch': 0, 'loss': 0.8832750916481018}\n",
      "{'epoch': 73, 'batch': 0, 'loss': 0.8376736640930176}\n",
      "{'epoch': 74, 'batch': 0, 'loss': 0.8347355127334595}\n",
      "{'epoch': 75, 'batch': 0, 'loss': 0.8098652362823486}\n",
      "{'epoch': 76, 'batch': 0, 'loss': 0.7598996162414551}\n",
      "{'epoch': 77, 'batch': 0, 'loss': 0.7255451083183289}\n",
      "{'epoch': 78, 'batch': 0, 'loss': 0.7044526934623718}\n",
      "{'epoch': 79, 'batch': 0, 'loss': 0.6815631985664368}\n",
      "{'epoch': 80, 'batch': 0, 'loss': 0.6611441969871521}\n",
      "{'epoch': 81, 'batch': 0, 'loss': 0.6352501511573792}\n",
      "{'epoch': 82, 'batch': 0, 'loss': 0.59096360206604}\n",
      "{'epoch': 83, 'batch': 0, 'loss': 0.5814385414123535}\n",
      "{'epoch': 84, 'batch': 0, 'loss': 0.5451573729515076}\n",
      "{'epoch': 85, 'batch': 0, 'loss': 0.5386833548545837}\n",
      "{'epoch': 86, 'batch': 0, 'loss': 0.5178064107894897}\n",
      "{'epoch': 87, 'batch': 0, 'loss': 0.4858438968658447}\n",
      "{'epoch': 88, 'batch': 0, 'loss': 0.45950138568878174}\n",
      "{'epoch': 89, 'batch': 0, 'loss': 0.44311287999153137}\n",
      "{'epoch': 90, 'batch': 0, 'loss': 0.44478943943977356}\n",
      "{'epoch': 91, 'batch': 0, 'loss': 0.38993844389915466}\n",
      "{'epoch': 92, 'batch': 0, 'loss': 0.3882365822792053}\n",
      "{'epoch': 93, 'batch': 0, 'loss': 0.3725760579109192}\n",
      "{'epoch': 94, 'batch': 0, 'loss': 0.37571603059768677}\n",
      "{'epoch': 95, 'batch': 0, 'loss': 0.36612433195114136}\n",
      "{'epoch': 96, 'batch': 0, 'loss': 0.33623382449150085}\n",
      "{'epoch': 97, 'batch': 0, 'loss': 0.30060938000679016}\n",
      "{'epoch': 98, 'batch': 0, 'loss': 0.31269505620002747}\n",
      "{'epoch': 99, 'batch': 0, 'loss': 0.29266634583473206}\n",
      "{'epoch': 100, 'batch': 0, 'loss': 0.28320732712745667}\n",
      "{'epoch': 101, 'batch': 0, 'loss': 0.28093335032463074}\n",
      "{'epoch': 102, 'batch': 0, 'loss': 0.27289023995399475}\n",
      "{'epoch': 103, 'batch': 0, 'loss': 0.24942611157894135}\n",
      "{'epoch': 104, 'batch': 0, 'loss': 0.2503489553928375}\n",
      "{'epoch': 105, 'batch': 0, 'loss': 0.23794302344322205}\n",
      "{'epoch': 106, 'batch': 0, 'loss': 0.22024840116500854}\n",
      "{'epoch': 107, 'batch': 0, 'loss': 0.20821864902973175}\n",
      "{'epoch': 108, 'batch': 0, 'loss': 0.20808681845664978}\n",
      "{'epoch': 109, 'batch': 0, 'loss': 0.20771470665931702}\n",
      "{'epoch': 110, 'batch': 0, 'loss': 0.18235178291797638}\n",
      "{'epoch': 111, 'batch': 0, 'loss': 0.19311614334583282}\n",
      "{'epoch': 112, 'batch': 0, 'loss': 0.17674221098423004}\n",
      "{'epoch': 113, 'batch': 0, 'loss': 0.17482860386371613}\n",
      "{'epoch': 114, 'batch': 0, 'loss': 0.17096596956253052}\n",
      "{'epoch': 115, 'batch': 0, 'loss': 0.15774355828762054}\n",
      "{'epoch': 116, 'batch': 0, 'loss': 0.1684645265340805}\n",
      "{'epoch': 117, 'batch': 0, 'loss': 0.15341788530349731}\n",
      "{'epoch': 118, 'batch': 0, 'loss': 0.151275172829628}\n",
      "{'epoch': 119, 'batch': 0, 'loss': 0.15570150315761566}\n",
      "{'epoch': 120, 'batch': 0, 'loss': 0.1401054710149765}\n",
      "{'epoch': 121, 'batch': 0, 'loss': 0.13673897087574005}\n",
      "{'epoch': 122, 'batch': 0, 'loss': 0.13132378458976746}\n",
      "{'epoch': 123, 'batch': 0, 'loss': 0.12524986267089844}\n",
      "{'epoch': 124, 'batch': 0, 'loss': 0.1260342001914978}\n",
      "{'epoch': 125, 'batch': 0, 'loss': 0.1232762336730957}\n",
      "{'epoch': 126, 'batch': 0, 'loss': 0.11988420784473419}\n",
      "{'epoch': 127, 'batch': 0, 'loss': 0.11350417137145996}\n",
      "{'epoch': 128, 'batch': 0, 'loss': 0.1188260018825531}\n",
      "{'epoch': 129, 'batch': 0, 'loss': 0.10674227029085159}\n",
      "{'epoch': 130, 'batch': 0, 'loss': 0.09970714896917343}\n",
      "{'epoch': 131, 'batch': 0, 'loss': 0.10513767600059509}\n",
      "{'epoch': 132, 'batch': 0, 'loss': 0.0962752252817154}\n",
      "{'epoch': 133, 'batch': 0, 'loss': 0.10123685747385025}\n",
      "{'epoch': 134, 'batch': 0, 'loss': 0.09342685341835022}\n",
      "{'epoch': 135, 'batch': 0, 'loss': 0.08886749297380447}\n",
      "{'epoch': 136, 'batch': 0, 'loss': 0.09237609803676605}\n",
      "{'epoch': 137, 'batch': 0, 'loss': 0.08499696105718613}\n",
      "{'epoch': 138, 'batch': 0, 'loss': 0.08224118500947952}\n",
      "{'epoch': 139, 'batch': 0, 'loss': 0.08289746195077896}\n",
      "{'epoch': 140, 'batch': 0, 'loss': 0.07810281217098236}\n",
      "{'epoch': 141, 'batch': 0, 'loss': 0.08793051540851593}\n",
      "{'epoch': 142, 'batch': 0, 'loss': 0.07789673656225204}\n",
      "{'epoch': 143, 'batch': 0, 'loss': 0.07824771851301193}\n",
      "{'epoch': 144, 'batch': 0, 'loss': 0.07381153106689453}\n",
      "{'epoch': 145, 'batch': 0, 'loss': 0.0729663148522377}\n",
      "{'epoch': 146, 'batch': 0, 'loss': 0.07045555114746094}\n",
      "{'epoch': 147, 'batch': 0, 'loss': 0.06728184223175049}\n",
      "{'epoch': 148, 'batch': 0, 'loss': 0.07189721614122391}\n",
      "{'epoch': 149, 'batch': 0, 'loss': 0.06709572672843933}\n",
      "{'epoch': 150, 'batch': 0, 'loss': 0.06544801592826843}\n",
      "{'epoch': 151, 'batch': 0, 'loss': 0.06417868286371231}\n",
      "{'epoch': 152, 'batch': 0, 'loss': 0.06615590304136276}\n",
      "{'epoch': 153, 'batch': 0, 'loss': 0.057642098516225815}\n",
      "{'epoch': 154, 'batch': 0, 'loss': 0.06119623780250549}\n",
      "{'epoch': 155, 'batch': 0, 'loss': 0.060240812599658966}\n",
      "{'epoch': 156, 'batch': 0, 'loss': 0.057148657739162445}\n",
      "{'epoch': 157, 'batch': 0, 'loss': 0.057642847299575806}\n",
      "{'epoch': 158, 'batch': 0, 'loss': 0.05617256090044975}\n",
      "{'epoch': 159, 'batch': 0, 'loss': 0.0540488138794899}\n",
      "{'epoch': 160, 'batch': 0, 'loss': 0.05758174508810043}\n",
      "{'epoch': 161, 'batch': 0, 'loss': 0.05561351776123047}\n",
      "{'epoch': 162, 'batch': 0, 'loss': 0.05284903943538666}\n",
      "{'epoch': 163, 'batch': 0, 'loss': 0.053852785378694534}\n",
      "{'epoch': 164, 'batch': 0, 'loss': 0.047746311873197556}\n",
      "{'epoch': 165, 'batch': 0, 'loss': 0.04910837486386299}\n",
      "{'epoch': 166, 'batch': 0, 'loss': 0.05234227702021599}\n",
      "{'epoch': 167, 'batch': 0, 'loss': 0.048080336302518845}\n",
      "{'epoch': 168, 'batch': 0, 'loss': 0.04533522203564644}\n",
      "{'epoch': 169, 'batch': 0, 'loss': 0.04649202525615692}\n",
      "{'epoch': 170, 'batch': 0, 'loss': 0.0465068519115448}\n",
      "{'epoch': 171, 'batch': 0, 'loss': 0.042306408286094666}\n",
      "{'epoch': 172, 'batch': 0, 'loss': 0.045710790902376175}\n",
      "{'epoch': 173, 'batch': 0, 'loss': 0.04450521618127823}\n",
      "{'epoch': 174, 'batch': 0, 'loss': 0.04176902770996094}\n",
      "{'epoch': 175, 'batch': 0, 'loss': 0.040857747197151184}\n",
      "{'epoch': 176, 'batch': 0, 'loss': 0.040957480669021606}\n",
      "{'epoch': 177, 'batch': 0, 'loss': 0.04245036095380783}\n",
      "{'epoch': 178, 'batch': 0, 'loss': 0.04029585048556328}\n",
      "{'epoch': 179, 'batch': 0, 'loss': 0.037405580282211304}\n",
      "{'epoch': 180, 'batch': 0, 'loss': 0.0379224456846714}\n",
      "{'epoch': 181, 'batch': 0, 'loss': 0.040712639689445496}\n",
      "{'epoch': 182, 'batch': 0, 'loss': 0.03629247844219208}\n",
      "{'epoch': 183, 'batch': 0, 'loss': 0.04043099284172058}\n",
      "{'epoch': 184, 'batch': 0, 'loss': 0.03713703528046608}\n",
      "{'epoch': 185, 'batch': 0, 'loss': 0.036269474774599075}\n",
      "{'epoch': 186, 'batch': 0, 'loss': 0.03556520491838455}\n",
      "{'epoch': 187, 'batch': 0, 'loss': 0.038273975253105164}\n",
      "{'epoch': 188, 'batch': 0, 'loss': 0.03440025448799133}\n",
      "{'epoch': 189, 'batch': 0, 'loss': 0.03318295627832413}\n",
      "{'epoch': 190, 'batch': 0, 'loss': 0.03599061444401741}\n",
      "{'epoch': 191, 'batch': 0, 'loss': 0.03325450047850609}\n",
      "{'epoch': 192, 'batch': 0, 'loss': 0.03164953365921974}\n",
      "{'epoch': 193, 'batch': 0, 'loss': 0.030994821339845657}\n",
      "{'epoch': 194, 'batch': 0, 'loss': 0.03579941764473915}\n",
      "{'epoch': 195, 'batch': 0, 'loss': 0.031603798270225525}\n",
      "{'epoch': 196, 'batch': 0, 'loss': 0.03249810263514519}\n",
      "{'epoch': 197, 'batch': 0, 'loss': 0.03209357708692551}\n",
      "{'epoch': 198, 'batch': 0, 'loss': 0.03463923558592796}\n",
      "{'epoch': 199, 'batch': 0, 'loss': 0.029744397848844528}\n",
      "{'epoch': 200, 'batch': 0, 'loss': 0.02914471924304962}\n",
      "{'epoch': 201, 'batch': 0, 'loss': 0.02979567088186741}\n",
      "{'epoch': 202, 'batch': 0, 'loss': 0.03039848804473877}\n",
      "{'epoch': 203, 'batch': 0, 'loss': 0.02650425396859646}\n",
      "{'epoch': 204, 'batch': 0, 'loss': 0.029356690123677254}\n",
      "{'epoch': 205, 'batch': 0, 'loss': 0.030165433883666992}\n",
      "{'epoch': 206, 'batch': 0, 'loss': 0.02831694670021534}\n",
      "{'epoch': 207, 'batch': 0, 'loss': 0.02588750794529915}\n",
      "{'epoch': 208, 'batch': 0, 'loss': 0.027724016457796097}\n",
      "{'epoch': 209, 'batch': 0, 'loss': 0.02648286148905754}\n",
      "{'epoch': 210, 'batch': 0, 'loss': 0.025955069810152054}\n",
      "{'epoch': 211, 'batch': 0, 'loss': 0.028485333546996117}\n",
      "{'epoch': 212, 'batch': 0, 'loss': 0.02795443683862686}\n",
      "{'epoch': 213, 'batch': 0, 'loss': 0.02467918209731579}\n",
      "{'epoch': 214, 'batch': 0, 'loss': 0.0251132994890213}\n",
      "{'epoch': 215, 'batch': 0, 'loss': 0.02653910592198372}\n",
      "{'epoch': 216, 'batch': 0, 'loss': 0.0246423427015543}\n",
      "{'epoch': 217, 'batch': 0, 'loss': 0.0272032730281353}\n",
      "{'epoch': 218, 'batch': 0, 'loss': 0.025258123874664307}\n",
      "{'epoch': 219, 'batch': 0, 'loss': 0.02526266500353813}\n",
      "{'epoch': 220, 'batch': 0, 'loss': 0.024395514279603958}\n",
      "{'epoch': 221, 'batch': 0, 'loss': 0.024603117257356644}\n",
      "{'epoch': 222, 'batch': 0, 'loss': 0.024173002690076828}\n",
      "{'epoch': 223, 'batch': 0, 'loss': 0.02345552295446396}\n",
      "{'epoch': 224, 'batch': 0, 'loss': 0.02432635985314846}\n",
      "{'epoch': 225, 'batch': 0, 'loss': 0.023821568116545677}\n",
      "{'epoch': 226, 'batch': 0, 'loss': 0.02333599328994751}\n",
      "{'epoch': 227, 'batch': 0, 'loss': 0.022360455244779587}\n",
      "{'epoch': 228, 'batch': 0, 'loss': 0.024255376309156418}\n",
      "{'epoch': 229, 'batch': 0, 'loss': 0.020297417417168617}\n",
      "{'epoch': 230, 'batch': 0, 'loss': 0.022802360355854034}\n",
      "{'epoch': 231, 'batch': 0, 'loss': 0.02193661965429783}\n",
      "{'epoch': 232, 'batch': 0, 'loss': 0.02241809293627739}\n",
      "{'epoch': 233, 'batch': 0, 'loss': 0.021035943180322647}\n",
      "{'epoch': 234, 'batch': 0, 'loss': 0.02162044495344162}\n",
      "{'epoch': 235, 'batch': 0, 'loss': 0.02107534185051918}\n",
      "{'epoch': 236, 'batch': 0, 'loss': 0.02006055787205696}\n",
      "{'epoch': 237, 'batch': 0, 'loss': 0.020632214844226837}\n",
      "{'epoch': 238, 'batch': 0, 'loss': 0.0225642379373312}\n",
      "{'epoch': 239, 'batch': 0, 'loss': 0.02158503606915474}\n",
      "{'epoch': 240, 'batch': 0, 'loss': 0.018432816490530968}\n",
      "{'epoch': 241, 'batch': 0, 'loss': 0.021716861054301262}\n",
      "{'epoch': 242, 'batch': 0, 'loss': 0.019227949902415276}\n",
      "{'epoch': 243, 'batch': 0, 'loss': 0.0204215906560421}\n",
      "{'epoch': 244, 'batch': 0, 'loss': 0.01934320107102394}\n",
      "{'epoch': 245, 'batch': 0, 'loss': 0.019929831847548485}\n",
      "{'epoch': 246, 'batch': 0, 'loss': 0.019937554374337196}\n",
      "{'epoch': 247, 'batch': 0, 'loss': 0.021095989271998405}\n",
      "{'epoch': 248, 'batch': 0, 'loss': 0.0222121961414814}\n",
      "{'epoch': 249, 'batch': 0, 'loss': 0.01839423179626465}\n",
      "{'epoch': 250, 'batch': 0, 'loss': 0.02198045328259468}\n",
      "{'epoch': 251, 'batch': 0, 'loss': 0.02035110630095005}\n",
      "{'epoch': 252, 'batch': 0, 'loss': 0.018438085913658142}\n",
      "{'epoch': 253, 'batch': 0, 'loss': 0.020140670239925385}\n",
      "{'epoch': 254, 'batch': 0, 'loss': 0.019598688930273056}\n",
      "{'epoch': 255, 'batch': 0, 'loss': 0.018405258655548096}\n",
      "{'epoch': 256, 'batch': 0, 'loss': 0.0190885029733181}\n",
      "{'epoch': 257, 'batch': 0, 'loss': 0.01754053123295307}\n",
      "{'epoch': 258, 'batch': 0, 'loss': 0.017422635108232498}\n",
      "{'epoch': 259, 'batch': 0, 'loss': 0.01807052455842495}\n",
      "{'epoch': 260, 'batch': 0, 'loss': 0.01649709790945053}\n",
      "{'epoch': 261, 'batch': 0, 'loss': 0.01734587922692299}\n",
      "{'epoch': 262, 'batch': 0, 'loss': 0.017433667555451393}\n",
      "{'epoch': 263, 'batch': 0, 'loss': 0.01694618910551071}\n",
      "{'epoch': 264, 'batch': 0, 'loss': 0.016105394810438156}\n",
      "{'epoch': 265, 'batch': 0, 'loss': 0.017082227393984795}\n",
      "{'epoch': 266, 'batch': 0, 'loss': 0.017522769048810005}\n",
      "{'epoch': 267, 'batch': 0, 'loss': 0.015288908034563065}\n",
      "{'epoch': 268, 'batch': 0, 'loss': 0.016274254769086838}\n",
      "{'epoch': 269, 'batch': 0, 'loss': 0.015925368294119835}\n",
      "{'epoch': 270, 'batch': 0, 'loss': 0.01725538820028305}\n",
      "{'epoch': 271, 'batch': 0, 'loss': 0.016297031193971634}\n",
      "{'epoch': 272, 'batch': 0, 'loss': 0.015257889404892921}\n",
      "{'epoch': 273, 'batch': 0, 'loss': 0.01714792475104332}\n",
      "{'epoch': 274, 'batch': 0, 'loss': 0.016381576657295227}\n",
      "{'epoch': 275, 'batch': 0, 'loss': 0.01626528427004814}\n",
      "{'epoch': 276, 'batch': 0, 'loss': 0.015747569501399994}\n",
      "{'epoch': 277, 'batch': 0, 'loss': 0.016130654141306877}\n",
      "{'epoch': 278, 'batch': 0, 'loss': 0.014493836089968681}\n",
      "{'epoch': 279, 'batch': 0, 'loss': 0.0157371386885643}\n",
      "{'epoch': 280, 'batch': 0, 'loss': 0.016633355990052223}\n",
      "{'epoch': 281, 'batch': 0, 'loss': 0.01463937759399414}\n",
      "{'epoch': 282, 'batch': 0, 'loss': 0.015911582857370377}\n",
      "{'epoch': 283, 'batch': 0, 'loss': 0.014727842062711716}\n",
      "{'epoch': 284, 'batch': 0, 'loss': 0.014870697632431984}\n",
      "{'epoch': 285, 'batch': 0, 'loss': 0.015163536183536053}\n",
      "{'epoch': 286, 'batch': 0, 'loss': 0.013215678744018078}\n",
      "{'epoch': 287, 'batch': 0, 'loss': 0.01484005805104971}\n",
      "{'epoch': 288, 'batch': 0, 'loss': 0.015166482888162136}\n",
      "{'epoch': 289, 'batch': 0, 'loss': 0.013694040477275848}\n",
      "{'epoch': 290, 'batch': 0, 'loss': 0.014830294996500015}\n",
      "{'epoch': 291, 'batch': 0, 'loss': 0.01439692359417677}\n",
      "{'epoch': 292, 'batch': 0, 'loss': 0.013297755271196365}\n",
      "{'epoch': 293, 'batch': 0, 'loss': 0.014650932513177395}\n",
      "{'epoch': 294, 'batch': 0, 'loss': 0.013531681150197983}\n",
      "{'epoch': 295, 'batch': 0, 'loss': 0.013601025566458702}\n",
      "{'epoch': 296, 'batch': 0, 'loss': 0.014595605432987213}\n",
      "{'epoch': 297, 'batch': 0, 'loss': 0.01350465789437294}\n",
      "{'epoch': 298, 'batch': 0, 'loss': 0.013077843934297562}\n",
      "{'epoch': 299, 'batch': 0, 'loss': 0.012637020088732243}\n",
      "{'epoch': 300, 'batch': 0, 'loss': 0.01362238172441721}\n",
      "{'epoch': 301, 'batch': 0, 'loss': 0.012033197097480297}\n",
      "{'epoch': 302, 'batch': 0, 'loss': 0.013290119357407093}\n",
      "{'epoch': 303, 'batch': 0, 'loss': 0.014660041779279709}\n",
      "{'epoch': 304, 'batch': 0, 'loss': 0.014840616844594479}\n",
      "{'epoch': 305, 'batch': 0, 'loss': 0.014541815966367722}\n",
      "{'epoch': 306, 'batch': 0, 'loss': 0.01285532210022211}\n",
      "{'epoch': 307, 'batch': 0, 'loss': 0.013039636425673962}\n",
      "{'epoch': 308, 'batch': 0, 'loss': 0.012943687848746777}\n",
      "{'epoch': 309, 'batch': 0, 'loss': 0.012220990844070911}\n",
      "{'epoch': 310, 'batch': 0, 'loss': 0.013188604265451431}\n",
      "{'epoch': 311, 'batch': 0, 'loss': 0.012193265371024609}\n",
      "{'epoch': 312, 'batch': 0, 'loss': 0.014462991617619991}\n",
      "{'epoch': 313, 'batch': 0, 'loss': 0.012860281392931938}\n",
      "{'epoch': 314, 'batch': 0, 'loss': 0.012954933568835258}\n",
      "{'epoch': 315, 'batch': 0, 'loss': 0.013184500858187675}\n",
      "{'epoch': 316, 'batch': 0, 'loss': 0.013144208118319511}\n",
      "{'epoch': 317, 'batch': 0, 'loss': 0.012866551987826824}\n",
      "{'epoch': 318, 'batch': 0, 'loss': 0.012491440400481224}\n",
      "{'epoch': 319, 'batch': 0, 'loss': 0.012714487500488758}\n",
      "{'epoch': 320, 'batch': 0, 'loss': 0.012783745303750038}\n",
      "{'epoch': 321, 'batch': 0, 'loss': 0.0124848373234272}\n",
      "{'epoch': 322, 'batch': 0, 'loss': 0.011535685509443283}\n",
      "{'epoch': 323, 'batch': 0, 'loss': 0.011553876101970673}\n",
      "{'epoch': 324, 'batch': 0, 'loss': 0.01219975482672453}\n",
      "{'epoch': 325, 'batch': 0, 'loss': 0.012783573009073734}\n",
      "{'epoch': 326, 'batch': 0, 'loss': 0.011584323830902576}\n",
      "{'epoch': 327, 'batch': 0, 'loss': 0.01110964547842741}\n",
      "{'epoch': 328, 'batch': 0, 'loss': 0.011981118470430374}\n",
      "{'epoch': 329, 'batch': 0, 'loss': 0.012538325972855091}\n",
      "{'epoch': 330, 'batch': 0, 'loss': 0.012437197379767895}\n",
      "{'epoch': 331, 'batch': 0, 'loss': 0.012039032764732838}\n",
      "{'epoch': 332, 'batch': 0, 'loss': 0.010616953484714031}\n",
      "{'epoch': 333, 'batch': 0, 'loss': 0.0110660120844841}\n",
      "{'epoch': 334, 'batch': 0, 'loss': 0.010903950780630112}\n",
      "{'epoch': 335, 'batch': 0, 'loss': 0.010705913417041302}\n",
      "{'epoch': 336, 'batch': 0, 'loss': 0.010889971628785133}\n",
      "{'epoch': 337, 'batch': 0, 'loss': 0.011996570974588394}\n",
      "{'epoch': 338, 'batch': 0, 'loss': 0.011617218144237995}\n",
      "{'epoch': 339, 'batch': 0, 'loss': 0.010610656812787056}\n",
      "{'epoch': 340, 'batch': 0, 'loss': 0.011749607510864735}\n",
      "{'epoch': 341, 'batch': 0, 'loss': 0.011606868356466293}\n",
      "{'epoch': 342, 'batch': 0, 'loss': 0.010087400674819946}\n",
      "{'epoch': 343, 'batch': 0, 'loss': 0.010642987675964832}\n",
      "{'epoch': 344, 'batch': 0, 'loss': 0.012476466596126556}\n",
      "{'epoch': 345, 'batch': 0, 'loss': 0.011519929394125938}\n",
      "{'epoch': 346, 'batch': 0, 'loss': 0.011483144015073776}\n",
      "{'epoch': 347, 'batch': 0, 'loss': 0.010719642974436283}\n",
      "{'epoch': 348, 'batch': 0, 'loss': 0.011120292358100414}\n",
      "{'epoch': 349, 'batch': 0, 'loss': 0.01009107194840908}\n",
      "{'epoch': 350, 'batch': 0, 'loss': 0.010370458476245403}\n",
      "{'epoch': 351, 'batch': 0, 'loss': 0.01114690862596035}\n",
      "{'epoch': 352, 'batch': 0, 'loss': 0.011561814695596695}\n",
      "{'epoch': 353, 'batch': 0, 'loss': 0.011348634958267212}\n",
      "{'epoch': 354, 'batch': 0, 'loss': 0.010841531679034233}\n",
      "{'epoch': 355, 'batch': 0, 'loss': 0.010454309172928333}\n",
      "{'epoch': 356, 'batch': 0, 'loss': 0.009991142898797989}\n",
      "{'epoch': 357, 'batch': 0, 'loss': 0.0108079444617033}\n",
      "{'epoch': 358, 'batch': 0, 'loss': 0.010358286090195179}\n",
      "{'epoch': 359, 'batch': 0, 'loss': 0.009833726100623608}\n",
      "{'epoch': 360, 'batch': 0, 'loss': 0.009341027587652206}\n",
      "{'epoch': 361, 'batch': 0, 'loss': 0.009686103090643883}\n",
      "{'epoch': 362, 'batch': 0, 'loss': 0.010569797828793526}\n",
      "{'epoch': 363, 'batch': 0, 'loss': 0.009684978052973747}\n",
      "{'epoch': 364, 'batch': 0, 'loss': 0.010723637416958809}\n",
      "{'epoch': 365, 'batch': 0, 'loss': 0.009361344389617443}\n",
      "{'epoch': 366, 'batch': 0, 'loss': 0.0094901816919446}\n",
      "{'epoch': 367, 'batch': 0, 'loss': 0.010257248766720295}\n",
      "{'epoch': 368, 'batch': 0, 'loss': 0.00981853436678648}\n",
      "{'epoch': 369, 'batch': 0, 'loss': 0.010246745310723782}\n",
      "{'epoch': 370, 'batch': 0, 'loss': 0.00888083130121231}\n",
      "{'epoch': 371, 'batch': 0, 'loss': 0.00904923863708973}\n",
      "{'epoch': 372, 'batch': 0, 'loss': 0.009210852906107903}\n",
      "{'epoch': 373, 'batch': 0, 'loss': 0.009142494760453701}\n",
      "{'epoch': 374, 'batch': 0, 'loss': 0.009587008506059647}\n",
      "{'epoch': 375, 'batch': 0, 'loss': 0.009684529155492783}\n",
      "{'epoch': 376, 'batch': 0, 'loss': 0.009610393084585667}\n",
      "{'epoch': 377, 'batch': 0, 'loss': 0.009818525984883308}\n",
      "{'epoch': 378, 'batch': 0, 'loss': 0.009761172346770763}\n",
      "{'epoch': 379, 'batch': 0, 'loss': 0.010296102613210678}\n",
      "{'epoch': 380, 'batch': 0, 'loss': 0.009683433920145035}\n",
      "{'epoch': 381, 'batch': 0, 'loss': 0.009662733413279057}\n",
      "{'epoch': 382, 'batch': 0, 'loss': 0.009868661873042583}\n",
      "{'epoch': 383, 'batch': 0, 'loss': 0.00887068547308445}\n",
      "{'epoch': 384, 'batch': 0, 'loss': 0.009299582801759243}\n",
      "{'epoch': 385, 'batch': 0, 'loss': 0.009707006625831127}\n",
      "{'epoch': 386, 'batch': 0, 'loss': 0.010364110581576824}\n",
      "{'epoch': 387, 'batch': 0, 'loss': 0.00870884582400322}\n",
      "{'epoch': 388, 'batch': 0, 'loss': 0.00906567182391882}\n",
      "{'epoch': 389, 'batch': 0, 'loss': 0.00912544410675764}\n",
      "{'epoch': 390, 'batch': 0, 'loss': 0.00785127654671669}\n",
      "{'epoch': 391, 'batch': 0, 'loss': 0.009358260780572891}\n",
      "{'epoch': 392, 'batch': 0, 'loss': 0.010128472931683064}\n",
      "{'epoch': 393, 'batch': 0, 'loss': 0.008815411478281021}\n",
      "{'epoch': 394, 'batch': 0, 'loss': 0.008874610997736454}\n",
      "{'epoch': 395, 'batch': 0, 'loss': 0.009138936176896095}\n",
      "{'epoch': 396, 'batch': 0, 'loss': 0.008657111786305904}\n",
      "{'epoch': 397, 'batch': 0, 'loss': 0.009135960601270199}\n",
      "{'epoch': 398, 'batch': 0, 'loss': 0.008345823734998703}\n",
      "{'epoch': 399, 'batch': 0, 'loss': 0.008345110341906548}\n",
      "{'epoch': 400, 'batch': 0, 'loss': 0.008471406996250153}\n",
      "{'epoch': 401, 'batch': 0, 'loss': 0.009390057064592838}\n",
      "{'epoch': 402, 'batch': 0, 'loss': 0.009873869828879833}\n",
      "{'epoch': 403, 'batch': 0, 'loss': 0.009069671854376793}\n",
      "{'epoch': 404, 'batch': 0, 'loss': 0.009054734371602535}\n",
      "{'epoch': 405, 'batch': 0, 'loss': 0.009195013903081417}\n",
      "{'epoch': 406, 'batch': 0, 'loss': 0.008696119301021099}\n",
      "{'epoch': 407, 'batch': 0, 'loss': 0.00950097106397152}\n",
      "{'epoch': 408, 'batch': 0, 'loss': 0.008780160918831825}\n",
      "{'epoch': 409, 'batch': 0, 'loss': 0.009786821901798248}\n",
      "{'epoch': 410, 'batch': 0, 'loss': 0.008289615623652935}\n",
      "{'epoch': 411, 'batch': 0, 'loss': 0.008871483616530895}\n",
      "{'epoch': 412, 'batch': 0, 'loss': 0.007978754118084908}\n",
      "{'epoch': 413, 'batch': 0, 'loss': 0.008365722373127937}\n",
      "{'epoch': 414, 'batch': 0, 'loss': 0.008893505670130253}\n",
      "{'epoch': 415, 'batch': 0, 'loss': 0.008939754217863083}\n",
      "{'epoch': 416, 'batch': 0, 'loss': 0.008247936144471169}\n",
      "{'epoch': 417, 'batch': 0, 'loss': 0.008070200681686401}\n",
      "{'epoch': 418, 'batch': 0, 'loss': 0.008220315910875797}\n",
      "{'epoch': 419, 'batch': 0, 'loss': 0.008335315622389317}\n",
      "{'epoch': 420, 'batch': 0, 'loss': 0.007913103327155113}\n",
      "{'epoch': 421, 'batch': 0, 'loss': 0.008492324501276016}\n",
      "{'epoch': 422, 'batch': 0, 'loss': 0.008464266546070576}\n",
      "{'epoch': 423, 'batch': 0, 'loss': 0.00833752378821373}\n",
      "{'epoch': 424, 'batch': 0, 'loss': 0.008089350536465645}\n",
      "{'epoch': 425, 'batch': 0, 'loss': 0.008198423311114311}\n",
      "{'epoch': 426, 'batch': 0, 'loss': 0.007713687606155872}\n",
      "{'epoch': 427, 'batch': 0, 'loss': 0.008386830799281597}\n",
      "{'epoch': 428, 'batch': 0, 'loss': 0.00814937986433506}\n",
      "{'epoch': 429, 'batch': 0, 'loss': 0.00812529306858778}\n",
      "{'epoch': 430, 'batch': 0, 'loss': 0.007553556468337774}\n",
      "{'epoch': 431, 'batch': 0, 'loss': 0.007986512966454029}\n",
      "{'epoch': 432, 'batch': 0, 'loss': 0.007834411226212978}\n",
      "{'epoch': 433, 'batch': 0, 'loss': 0.007900601252913475}\n",
      "{'epoch': 434, 'batch': 0, 'loss': 0.008372393436729908}\n",
      "{'epoch': 435, 'batch': 0, 'loss': 0.007535603828728199}\n",
      "{'epoch': 436, 'batch': 0, 'loss': 0.007468078751116991}\n",
      "{'epoch': 437, 'batch': 0, 'loss': 0.008070679381489754}\n",
      "{'epoch': 438, 'batch': 0, 'loss': 0.007713508792221546}\n",
      "{'epoch': 439, 'batch': 0, 'loss': 0.0076292878948152065}\n",
      "{'epoch': 440, 'batch': 0, 'loss': 0.007884559221565723}\n",
      "{'epoch': 441, 'batch': 0, 'loss': 0.007659588940441608}\n",
      "{'epoch': 442, 'batch': 0, 'loss': 0.008260807022452354}\n",
      "{'epoch': 443, 'batch': 0, 'loss': 0.006373826414346695}\n",
      "{'epoch': 444, 'batch': 0, 'loss': 0.008498149923980236}\n",
      "{'epoch': 445, 'batch': 0, 'loss': 0.007638589944690466}\n",
      "{'epoch': 446, 'batch': 0, 'loss': 0.006799512542784214}\n",
      "{'epoch': 447, 'batch': 0, 'loss': 0.00668569328263402}\n",
      "{'epoch': 448, 'batch': 0, 'loss': 0.00791805051267147}\n",
      "{'epoch': 449, 'batch': 0, 'loss': 0.007941953837871552}\n",
      "{'epoch': 450, 'batch': 0, 'loss': 0.007716051768511534}\n",
      "{'epoch': 451, 'batch': 0, 'loss': 0.006981185171753168}\n",
      "{'epoch': 452, 'batch': 0, 'loss': 0.007475837599486113}\n",
      "{'epoch': 453, 'batch': 0, 'loss': 0.007060997653752565}\n",
      "{'epoch': 454, 'batch': 0, 'loss': 0.007993834093213081}\n",
      "{'epoch': 455, 'batch': 0, 'loss': 0.008168954402208328}\n",
      "{'epoch': 456, 'batch': 0, 'loss': 0.007297170348465443}\n",
      "{'epoch': 457, 'batch': 0, 'loss': 0.007031701970845461}\n",
      "{'epoch': 458, 'batch': 0, 'loss': 0.006837040651589632}\n",
      "{'epoch': 459, 'batch': 0, 'loss': 0.007778785191476345}\n",
      "{'epoch': 460, 'batch': 0, 'loss': 0.007466109003871679}\n",
      "{'epoch': 461, 'batch': 0, 'loss': 0.00772631773725152}\n",
      "{'epoch': 462, 'batch': 0, 'loss': 0.00762737262994051}\n",
      "{'epoch': 463, 'batch': 0, 'loss': 0.007129409816116095}\n",
      "{'epoch': 464, 'batch': 0, 'loss': 0.0070290653966367245}\n",
      "{'epoch': 465, 'batch': 0, 'loss': 0.006868560798466206}\n",
      "{'epoch': 466, 'batch': 0, 'loss': 0.007100933231413364}\n",
      "{'epoch': 467, 'batch': 0, 'loss': 0.00791112519800663}\n",
      "{'epoch': 468, 'batch': 0, 'loss': 0.008184440433979034}\n",
      "{'epoch': 469, 'batch': 0, 'loss': 0.007368471473455429}\n",
      "{'epoch': 470, 'batch': 0, 'loss': 0.006995076313614845}\n",
      "{'epoch': 471, 'batch': 0, 'loss': 0.006629494484513998}\n",
      "{'epoch': 472, 'batch': 0, 'loss': 0.006816107779741287}\n",
      "{'epoch': 473, 'batch': 0, 'loss': 0.006676431279629469}\n",
      "{'epoch': 474, 'batch': 0, 'loss': 0.007642051205039024}\n",
      "{'epoch': 475, 'batch': 0, 'loss': 0.0067223310470581055}\n",
      "{'epoch': 476, 'batch': 0, 'loss': 0.007344289217144251}\n",
      "{'epoch': 477, 'batch': 0, 'loss': 0.007435755804181099}\n",
      "{'epoch': 478, 'batch': 0, 'loss': 0.0071907974779605865}\n",
      "{'epoch': 479, 'batch': 0, 'loss': 0.007520201615989208}\n",
      "{'epoch': 480, 'batch': 0, 'loss': 0.007202157285064459}\n",
      "{'epoch': 481, 'batch': 0, 'loss': 0.007286224514245987}\n",
      "{'epoch': 482, 'batch': 0, 'loss': 0.007590825669467449}\n",
      "{'epoch': 483, 'batch': 0, 'loss': 0.007068157661706209}\n",
      "{'epoch': 484, 'batch': 0, 'loss': 0.007221270818263292}\n",
      "{'epoch': 485, 'batch': 0, 'loss': 0.00809104647487402}\n",
      "{'epoch': 486, 'batch': 0, 'loss': 0.006466086488217115}\n",
      "{'epoch': 487, 'batch': 0, 'loss': 0.005963718518614769}\n",
      "{'epoch': 488, 'batch': 0, 'loss': 0.007636398542672396}\n",
      "{'epoch': 489, 'batch': 0, 'loss': 0.007291322574019432}\n",
      "{'epoch': 490, 'batch': 0, 'loss': 0.006592623423784971}\n",
      "{'epoch': 491, 'batch': 0, 'loss': 0.0065971906296908855}\n",
      "{'epoch': 492, 'batch': 0, 'loss': 0.00788371916860342}\n",
      "{'epoch': 493, 'batch': 0, 'loss': 0.007186155300587416}\n",
      "{'epoch': 494, 'batch': 0, 'loss': 0.00796058401465416}\n",
      "{'epoch': 495, 'batch': 0, 'loss': 0.006186384707689285}\n",
      "{'epoch': 496, 'batch': 0, 'loss': 0.008182687684893608}\n",
      "{'epoch': 497, 'batch': 0, 'loss': 0.006901427637785673}\n",
      "{'epoch': 498, 'batch': 0, 'loss': 0.007579164579510689}\n",
      "{'epoch': 499, 'batch': 0, 'loss': 0.0065509118139743805}\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "model = utils.LSTMModel(50, 300, len(vocab), device, 1).cuda()\n",
    "model = model.to(device)\n",
    "utils.train_loop(model, train_data_batched, batch_size=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_16072/1323123842.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtext\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgenerate_text\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvocab\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'იკვლევდა ევროპას და განსაკუთრებით'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m20\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/university/NLP-Final-Project/utils.py\u001B[0m in \u001B[0;36mgenerate_text\u001B[0;34m(model, device, vocab, context, length)\u001B[0m\n\u001B[1;32m    354\u001B[0m         \u001B[0mp\u001B[0m \u001B[0;34m/=\u001B[0m \u001B[0mp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    355\u001B[0m         \u001B[0mword_index\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrandom\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchoice\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlast_word_logits\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mp\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mp\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 356\u001B[0;31m         \u001B[0mwords\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvocab\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_itos\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mword_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    357\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    358\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0;34m''\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mwords\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "text = utils.generate_text(model,device, dataset.vocab, 'იკვლევდა ევროპას და განსაკუთრებით', 20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['იკვლევდა', 'ევროპას', 'და', 'განსაკუთრებით', 'ურიგებს', 'ასპარეზი', ',', 'კირქვისა', ',', 'ანდეზიტ-ბაზალტის', 'გურიელი', 'სამრეკლოს', ',', 'გურიელი', ',', 'და', 'სამრეკლოს', ',', 'გურიელი', 'სამრეკლოს', 'სამრეკლოს', 'კირქვისა', 'ანდეზიტ-ბაზალტის', 'ანდეზიტ-ბაზალტის']\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "# dataset = GeorgianLanguageDatasetLoader(\"../data/kawiki.txt\", 5, device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing data\n",
      "Model created!\n"
     ]
    }
   ],
   "source": [
    "# geo_model = utils.GeorgianWord2VecModel(load=True)\n",
    "# # geo_model.train(\"../data/kawiki.txt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# embeddings = torch.FloatTensor(geo_model.get_model().wv.vectors)\n",
    "# # embeddings.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misho/anaconda3/envs/nlp_final_project/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'batch': 0, 'loss': 11.625279426574707}\n",
      "{'epoch': 1, 'batch': 0, 'loss': 11.495043754577637}\n",
      "{'epoch': 2, 'batch': 0, 'loss': 11.313353538513184}\n",
      "{'epoch': 3, 'batch': 0, 'loss': 10.92991828918457}\n",
      "{'epoch': 4, 'batch': 0, 'loss': 9.908686637878418}\n",
      "{'epoch': 5, 'batch': 0, 'loss': 7.984778881072998}\n",
      "{'epoch': 6, 'batch': 0, 'loss': 5.963374614715576}\n",
      "{'epoch': 7, 'batch': 0, 'loss': 4.460447788238525}\n",
      "{'epoch': 8, 'batch': 0, 'loss': 3.8317975997924805}\n",
      "{'epoch': 9, 'batch': 0, 'loss': 3.6052162647247314}\n",
      "{'epoch': 10, 'batch': 0, 'loss': 3.578481674194336}\n",
      "{'epoch': 11, 'batch': 0, 'loss': 3.5857133865356445}\n",
      "{'epoch': 12, 'batch': 0, 'loss': 3.607102632522583}\n",
      "{'epoch': 13, 'batch': 0, 'loss': 3.566080331802368}\n",
      "{'epoch': 14, 'batch': 0, 'loss': 3.5081725120544434}\n",
      "{'epoch': 15, 'batch': 0, 'loss': 3.4336776733398438}\n",
      "{'epoch': 16, 'batch': 0, 'loss': 3.3940911293029785}\n",
      "{'epoch': 17, 'batch': 0, 'loss': 3.3870580196380615}\n",
      "{'epoch': 18, 'batch': 0, 'loss': 3.3852837085723877}\n",
      "{'epoch': 19, 'batch': 0, 'loss': 3.3679115772247314}\n",
      "{'epoch': 20, 'batch': 0, 'loss': 3.313447952270508}\n",
      "{'epoch': 21, 'batch': 0, 'loss': 3.2777175903320312}\n",
      "{'epoch': 22, 'batch': 0, 'loss': 3.2579171657562256}\n",
      "{'epoch': 23, 'batch': 0, 'loss': 3.23781156539917}\n",
      "{'epoch': 24, 'batch': 0, 'loss': 3.212456464767456}\n",
      "{'epoch': 25, 'batch': 0, 'loss': 3.1781082153320312}\n",
      "{'epoch': 26, 'batch': 0, 'loss': 3.1456429958343506}\n",
      "{'epoch': 27, 'batch': 0, 'loss': 3.118100643157959}\n",
      "{'epoch': 28, 'batch': 0, 'loss': 3.0956649780273438}\n",
      "{'epoch': 29, 'batch': 0, 'loss': 3.0580997467041016}\n",
      "{'epoch': 30, 'batch': 0, 'loss': 3.043342351913452}\n",
      "{'epoch': 31, 'batch': 0, 'loss': 3.0043387413024902}\n",
      "{'epoch': 32, 'batch': 0, 'loss': 2.953369140625}\n",
      "{'epoch': 33, 'batch': 0, 'loss': 2.9520840644836426}\n",
      "{'epoch': 34, 'batch': 0, 'loss': 2.9003593921661377}\n",
      "{'epoch': 35, 'batch': 0, 'loss': 2.875326156616211}\n",
      "{'epoch': 36, 'batch': 0, 'loss': 2.844968318939209}\n",
      "{'epoch': 37, 'batch': 0, 'loss': 2.8012800216674805}\n",
      "{'epoch': 38, 'batch': 0, 'loss': 2.7512238025665283}\n",
      "{'epoch': 39, 'batch': 0, 'loss': 2.7281246185302734}\n",
      "{'epoch': 40, 'batch': 0, 'loss': 2.6793651580810547}\n",
      "{'epoch': 41, 'batch': 0, 'loss': 2.636470317840576}\n",
      "{'epoch': 42, 'batch': 0, 'loss': 2.625300645828247}\n",
      "{'epoch': 43, 'batch': 0, 'loss': 2.598043203353882}\n",
      "{'epoch': 44, 'batch': 0, 'loss': 2.5626320838928223}\n",
      "{'epoch': 45, 'batch': 0, 'loss': 2.511591911315918}\n",
      "{'epoch': 46, 'batch': 0, 'loss': 2.4884161949157715}\n",
      "{'epoch': 47, 'batch': 0, 'loss': 2.4439263343811035}\n",
      "{'epoch': 48, 'batch': 0, 'loss': 2.3971357345581055}\n",
      "{'epoch': 49, 'batch': 0, 'loss': 2.367974042892456}\n",
      "{'epoch': 50, 'batch': 0, 'loss': 2.315941572189331}\n",
      "{'epoch': 51, 'batch': 0, 'loss': 2.2805089950561523}\n",
      "{'epoch': 52, 'batch': 0, 'loss': 2.2624008655548096}\n",
      "{'epoch': 53, 'batch': 0, 'loss': 2.2004823684692383}\n",
      "{'epoch': 54, 'batch': 0, 'loss': 2.1653194427490234}\n",
      "{'epoch': 55, 'batch': 0, 'loss': 2.11392879486084}\n",
      "{'epoch': 56, 'batch': 0, 'loss': 2.1087889671325684}\n",
      "{'epoch': 57, 'batch': 0, 'loss': 2.065166711807251}\n",
      "{'epoch': 58, 'batch': 0, 'loss': 2.039245843887329}\n",
      "{'epoch': 59, 'batch': 0, 'loss': 2.0682899951934814}\n",
      "{'epoch': 60, 'batch': 0, 'loss': 1.9500846862792969}\n",
      "{'epoch': 61, 'batch': 0, 'loss': 1.9129787683486938}\n",
      "{'epoch': 62, 'batch': 0, 'loss': 1.8677988052368164}\n",
      "{'epoch': 63, 'batch': 0, 'loss': 1.8423984050750732}\n",
      "{'epoch': 64, 'batch': 0, 'loss': 1.807019829750061}\n",
      "{'epoch': 65, 'batch': 0, 'loss': 1.7546720504760742}\n",
      "{'epoch': 66, 'batch': 0, 'loss': 1.701263427734375}\n",
      "{'epoch': 67, 'batch': 0, 'loss': 1.6840020418167114}\n",
      "{'epoch': 68, 'batch': 0, 'loss': 1.622675895690918}\n",
      "{'epoch': 69, 'batch': 0, 'loss': 1.5906444787979126}\n",
      "{'epoch': 70, 'batch': 0, 'loss': 1.5386860370635986}\n",
      "{'epoch': 71, 'batch': 0, 'loss': 1.5079851150512695}\n",
      "{'epoch': 72, 'batch': 0, 'loss': 1.4470311403274536}\n",
      "{'epoch': 73, 'batch': 0, 'loss': 1.443363070487976}\n",
      "{'epoch': 74, 'batch': 0, 'loss': 1.3683311939239502}\n",
      "{'epoch': 75, 'batch': 0, 'loss': 1.3418340682983398}\n",
      "{'epoch': 76, 'batch': 0, 'loss': 1.3083479404449463}\n",
      "{'epoch': 77, 'batch': 0, 'loss': 1.263794183731079}\n",
      "{'epoch': 78, 'batch': 0, 'loss': 1.2238141298294067}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_16072/3052244950.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mLSTMModel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m128\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m600\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvocab\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_layers\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0membeddings\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0membeddings\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_loop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_data_batched\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/university/NLP-Final-Project/utils.py\u001B[0m in \u001B[0;36mtrain_loop\u001B[0;34m(model, batch_data, batch_size, bptt)\u001B[0m\n\u001B[1;32m    327\u001B[0m             \u001B[0;31m# y_pred has shape (batch_size, max_seq_len, vocab_size), y has shape (batch_size, max_seq_len), and we\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    328\u001B[0m             \u001B[0;31m# need to compute average Cross Entropy across batch and sequence dimensions. For this, we first reshape tensors accordingly.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 329\u001B[0;31m             \u001B[0my_pred\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mstate_h\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstate_c\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mstate_h\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstate_c\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    330\u001B[0m             \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcrit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_pred\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtranspose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    331\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/nlp_final_project/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1131\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/university/NLP-Final-Project/utils.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, inp, prev_state)\u001B[0m\n\u001B[1;32m    250\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    251\u001B[0m         \u001B[0mout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstate\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlstm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0memb\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprev_state\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 252\u001B[0;31m         \u001B[0mlogits\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclassifier\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    253\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mlogits\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstate\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    254\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/nlp_final_project/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1131\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/nlp_final_project/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    113\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 114\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    115\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mextra_repr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# %reload_ext autoreload\n",
    "#\n",
    "# model = utils.LSTMModel(128, 600, len(vocab), device, num_layers=1, embeddings=embeddings).cuda()\n",
    "# model = model.to(device)\n",
    "# utils.train_loop(model, train_data_batched, batch_size=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import torchtext\n",
    "# v = torchtext.vocab.vocab(geo_model.get_model().wv.key_to_index, specials=['<unk>'])\n",
    "# v.set_default_index(v['<unk>'])\n",
    "# # dataset.vocab.load_state_dict(geo_model.get_model().wv.key_to_index)\n",
    "# text = utils.generate_text(model,device, v, 'იკვლევდა ევროპას და განსაკუთრებით', 10)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_final_project",
   "language": "python",
   "name": "nlp_final_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}